{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6c46a7-79db-4c1f-9a5d-81e362191434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit \n",
    "import pycuda.driver as cuda\n",
    "import tensorrt as trt\n",
    "import torch \n",
    "import time \n",
    "from PIL import Image\n",
    "import cv2,os\n",
    "import torchvision \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed6a29-96bf-4932-8ffd-0388507d826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_np_nchw(img_path):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = np.asarray(img, dtype='float32')\n",
    "    img = cv2.resize(np.array(img),(224, 224), interpolation = cv2.INTER_CUBIC)\n",
    "    img = img / 255.\n",
    "    img = img[np.newaxis, np.newaxis]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb127d4a-748e-4ca5-b7e4-b91f02efe276",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_img_np_nchw('/home/workspace/iot_ai_model/dataset/casting_data/test/defect/cast_def_0_1137.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820ae202-8d91-4c8b-98fe-2f9b0597bbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.67058814, 0.67058825, 0.67058825, ..., 0.6820318 ,\n",
       "          0.68235296, 0.6823529 ],\n",
       "         [0.6709623 , 0.67096233, 0.67096233, ..., 0.68203175,\n",
       "          0.68235296, 0.6823529 ],\n",
       "         [0.667174  , 0.667174  , 0.667174  , ..., 0.68203175,\n",
       "          0.68235296, 0.6823529 ],\n",
       "         ...,\n",
       "         [0.60334754, 0.60001314, 0.59658575, ..., 0.6431372 ,\n",
       "          0.6431372 , 0.6431372 ],\n",
       "         [0.60334754, 0.60001314, 0.59658575, ..., 0.6431373 ,\n",
       "          0.6431373 , 0.64313734],\n",
       "         [0.60334754, 0.60001314, 0.59658575, ..., 0.6431373 ,\n",
       "          0.6431373 , 0.6431373 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fca7000-b649-4ef8-a5dc-5e192ff89ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/workspace/iot_ai_model/inceptionv4_trt.engine', 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "# engine = trt_runtime.deserialize_cuda_engine(engine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07754b2-9fb0-4783-9c40-b2560e3da9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c982b0-31c7-45ac-b79e-a64e28aa9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = runtime.deserialize_cuda_engine(engine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f90521-19ac-4af6-960f-7f459a80a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e49c49-5f95-40ea-a64a-1ca25ca40a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7550f4bf-d5e7-475f-a1f7-71546f13fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1,2,4],[1,2,4],[1,2,4]],[[1,2,4],[1,2,4],[1,2,4]],[[1,2,4],[1,2,4],[1,2,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc0a8837-f93c-4cdd-8e89-31852637c8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.2489083 ,  6.89285714, 15.97333333],\n",
       "        [ 2.2489083 ,  6.89285714, 15.97333333],\n",
       "        [ 2.2489083 ,  6.89285714, 15.97333333]],\n",
       "\n",
       "       [[ 2.2489083 ,  6.89285714, 15.97333333],\n",
       "        [ 2.2489083 ,  6.89285714, 15.97333333],\n",
       "        [ 2.2489083 ,  6.89285714, 15.97333333]],\n",
       "\n",
       "       [[ 2.2489083 ,  6.89285714, 15.97333333],\n",
       "        [ 2.2489083 ,  6.89285714, 15.97333333],\n",
       "        [ 2.2489083 ,  6.89285714, 15.97333333]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6923d43-9449-4ed2-ad6f-1bde32c7cbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edfbae58-f03c-41bc-8632-3363188bbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "665a378e-85a0-41b9-a83a-bbf411d678c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('dataset/casting_data/test/defect/cast_def_0_1493.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f371aca-daef-45ff-809b-4ba7f7daeafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img.resize((224,224)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30b74c91-5fb1-4e5b-9d2a-46deddaeddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img * (1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33d0f475-bb02-40fd-b145-6ecb13dc1b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.68283771, 0.75169029, 0.85542726],\n",
       "        [0.68283771, 0.75169029, 0.85542726],\n",
       "        [0.69103258, 0.75997611, 0.86369465],\n",
       "        ...,\n",
       "        [0.38782227, 0.45340044, 0.55780102],\n",
       "        [0.38782227, 0.45340044, 0.55780102],\n",
       "        [0.38782227, 0.45340044, 0.55780102]],\n",
       "\n",
       "       [[0.68283771, 0.75169029, 0.85542726],\n",
       "        [0.68283771, 0.75169029, 0.85542726],\n",
       "        [0.69103258, 0.75997611, 0.86369465],\n",
       "        ...,\n",
       "        [0.38782227, 0.45340044, 0.55780102],\n",
       "        [0.38782227, 0.45340044, 0.55780102],\n",
       "        [0.38782227, 0.45340044, 0.55780102]],\n",
       "\n",
       "       [[0.68283771, 0.75169029, 0.85542726],\n",
       "        [0.68283771, 0.75169029, 0.85542726],\n",
       "        [0.69103258, 0.75997611, 0.86369465],\n",
       "        ...,\n",
       "        [0.38782227, 0.45340044, 0.55780102],\n",
       "        [0.38782227, 0.45340044, 0.55780102],\n",
       "        [0.38782227, 0.45340044, 0.55780102]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.6582531 , 0.72683281, 0.83062508],\n",
       "        [0.6582531 , 0.72683281, 0.83062508],\n",
       "        [0.6582531 , 0.72683281, 0.83062508],\n",
       "        ...,\n",
       "        [0.30587358, 0.37054219, 0.4751271 ],\n",
       "        [0.30587358, 0.37054219, 0.4751271 ],\n",
       "        [0.30587358, 0.37054219, 0.4751271 ]],\n",
       "\n",
       "       [[0.65005823, 0.71854698, 0.82235769],\n",
       "        [0.65005823, 0.71854698, 0.82235769],\n",
       "        [0.65005823, 0.71854698, 0.82235769],\n",
       "        ...,\n",
       "        [0.30587358, 0.37054219, 0.4751271 ],\n",
       "        [0.30587358, 0.37054219, 0.4751271 ],\n",
       "        [0.30587358, 0.37054219, 0.4751271 ]],\n",
       "\n",
       "       [[0.63366849, 0.70197533, 0.80582291],\n",
       "        [0.63366849, 0.70197533, 0.80582291],\n",
       "        [0.63366849, 0.70197533, 0.80582291],\n",
       "        ...,\n",
       "        [0.30587358, 0.37054219, 0.4751271 ],\n",
       "        [0.30587358, 0.37054219, 0.4751271 ],\n",
       "        [0.30587358, 0.37054219, 0.4751271 ]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img - [0.485, 0.456, 0.406]) / np.sqrt([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ea7b979-e29c-4486-86a3-1ae3360c315b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.one_hot(torch.tensor(0), 10).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13a585-c28f-465b-b805-d6ddf7a2b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging file path : check_points/rnn/train.log\n",
      "training device : cuda\n",
      "Namespace(batch_size=256, cpus=-1, epochs=50, hidden_dim=8, layers=2, lr=0.01, name='rnn', random_seed=45, use_cpu=False)\n",
      "data size - trn : 98663, val : 24666\n",
      "100%|#############################| 386/386 [01:22<00:00,  4.67it/s, loss=0.974]\n",
      "trn Epoch:  1, time : 82.75, loss : 1.1106, f1-score : 0.5569\n",
      "100%|#############################################| 3/3 [01:36<00:00, 32.27s/it]\n",
      "best f1! save model. check_points/rnn/model_state_dict_best.pt\n",
      "val Epoch:  1, time : 96.91, loss : 0.0071, f1-score : 0.6193\n",
      "100%|#############################| 386/386 [01:24<00:00,  4.59it/s, loss=0.548]\n",
      "trn Epoch:  2, time : 84.14, loss : 0.7331, f1-score : 0.6684\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!python3 ./model/pytorch/rnn/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437a6fe-dc1e-471a-8ee9-7dcb80d0bd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging file path : check_points/lstm/train.log\n",
      "training device : cuda\n",
      "Namespace(batch_size=512, cpus=-1, epochs=50, lr=0.0001, name='lstm', random_seed=45, use_cpu=False)\n",
      "data size - trn : 112837, val : 28210\n",
      "loaded weight: check_points/lstm/model_state_dict_best.pt\n",
      "100%|############################| 221/221 [00:46<00:00,  4.78it/s, loss=0.0794]\n",
      "trn Epoch:  1, time : 46.23, loss : 0.1111, f1-score : 0.9575\n",
      "100%|#############################################| 3/3 [00:41<00:00, 13.71s/it]\n",
      "best f1! save model. check_points/lstm/model_state_dict_best.pt\n",
      "val Epoch:  1, time : 41.15, loss : 0.0015, f1-score : 0.9587\n",
      "100%|#############################| 221/221 [00:45<00:00,  4.87it/s, loss=0.159]\n",
      "trn Epoch:  2, time : 45.36, loss : 0.1101, f1-score : 0.9570\n",
      "100%|#############################################| 3/3 [00:41<00:00, 13.82s/it]\n",
      "best f1! save model. check_points/lstm/model_state_dict_best.pt\n",
      "val Epoch:  2, time : 41.49, loss : 0.0014, f1-score : 0.9594\n",
      " 77%|######################3      | 170/221 [00:35<00:05,  8.82it/s, loss=0.157]"
     ]
    }
   ],
   "source": [
    "!python3 ./model/pytorch/lstm/train.py --lr 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f10705-f78c-4580-a444-0cd1d15d5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./model/pytorch/lstm/predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5822fd5-e180-49c4-8caf-4212e5478129",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./model/pytorch/rnn/predict.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
