{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zliPvDV8076V",
   "metadata": {
    "id": "zliPvDV8076V"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp -rf /content/drive/MyDrive/colab/didimdol/* .\n",
    "!unzip  /content/dataset/dataset.zip -d ./dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1c04b2-6085-4b87-8973-167c3b85eb21",
   "metadata": {
    "id": "de1c04b2-6085-4b87-8973-167c3b85eb21"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yMJFStLOHhfx",
   "metadata": {
    "id": "yMJFStLOHhfx"
   },
   "source": [
    "# 모델 로딩 및 binary classification 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c10269-cb64-47be-b45e-ec988878347f",
   "metadata": {
    "id": "75c10269-cb64-47be-b45e-ec988878347f"
   },
   "outputs": [],
   "source": [
    "model = resnet50.ResNet50(weights=None, classes = 1, classifier_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bs1GwjvNJWcv",
   "metadata": {
    "id": "bs1GwjvNJWcv"
   },
   "source": [
    "# 학습데이터 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5cca85-25ec-4e23-8a72-f77dc58bc35b",
   "metadata": {
    "id": "ed5cca85-25ec-4e23-8a72-f77dc58bc35b"
   },
   "outputs": [],
   "source": [
    "trn_data_dir = 'dataset/casting_data/train'\n",
    "val_data_dir = 'dataset/casting_data/test'\n",
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad09cab-56fb-4e56-9b99-c2f339e359b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bad09cab-56fb-4e56-9b99-c2f339e359b1",
    "outputId": "3d8157db-c70a-4189-852a-c77f2184e4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6633 files belonging to 2 classes.\n",
      "Found 715 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = preprocessing.image_dataset_from_directory(\n",
    "    trn_data_dir,\n",
    "    label_mode = 'binary',\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_data_dir,\n",
    "    #validation_split=0.2,\n",
    "    label_mode = 'binary',\n",
    "    #subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "RWa2b7uabkZT",
   "metadata": {
    "id": "RWa2b7uabkZT"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    keras.layers.experimental.preprocessing.Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229, 0.224, 0.225]),\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"vertical\",   input_shape=(img_height, img_width, 3)),\n",
    "  ]\n",
    ")\n",
    "\n",
    "test_processing = keras.Sequential(\n",
    "  [\n",
    "    keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    keras.layers.experimental.preprocessing.Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229, 0.224, 0.225])\n",
    "  ]\n",
    ")\n",
    "\n",
    "normalized_trn_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
    "normalized_test_ds = test_ds.map(lambda x, y: (test_processing(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pHgoXr7_Jb3m",
   "metadata": {
    "id": "pHgoXr7_Jb3m"
   },
   "source": [
    "# 모델 학습 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "156cd22b-bd1e-4679-9d22-922845ca4cc2",
   "metadata": {
    "id": "156cd22b-bd1e-4679-9d22-922845ca4cc2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2BxBdqMb-DhC",
   "metadata": {
    "id": "2BxBdqMb-DhC"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('check_points/resnet50/model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hsMbozktHR7c",
   "metadata": {
    "id": "hsMbozktHR7c"
   },
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483d54a7-e19f-4f71-95fa-c869d86756f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "483d54a7-e19f-4f71-95fa-c869d86756f4",
    "outputId": "6b87067b-be07-4237-e9f3-f9120847a940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "104/104 [==============================] - 59s 505ms/step - loss: 0.3618 - binary_accuracy: 0.8961 - val_loss: 1.2958 - val_binary_accuracy: 0.4210\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29584, saving model to check_points/resnet50/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "104/104 [==============================] - 51s 487ms/step - loss: 0.1081 - binary_accuracy: 0.9616 - val_loss: 2.5459 - val_binary_accuracy: 0.6294\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.29584\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 51s 486ms/step - loss: 0.0610 - binary_accuracy: 0.9809 - val_loss: 12.3210 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.29584\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 51s 489ms/step - loss: 0.0366 - binary_accuracy: 0.9894 - val_loss: 0.5074 - val_binary_accuracy: 0.8685\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.29584 to 0.50738, saving model to check_points/resnet50/model.h5\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 51s 489ms/step - loss: 0.0388 - binary_accuracy: 0.9891 - val_loss: 0.6076 - val_binary_accuracy: 0.8056\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.50738\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 51s 487ms/step - loss: 0.0284 - binary_accuracy: 0.9934 - val_loss: 3.8538 - val_binary_accuracy: 0.6476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.50738\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 51s 489ms/step - loss: 0.0262 - binary_accuracy: 0.9916 - val_loss: 0.3150 - val_binary_accuracy: 0.8867\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.50738 to 0.31499, saving model to check_points/resnet50/model.h5\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 51s 490ms/step - loss: 0.0266 - binary_accuracy: 0.9932 - val_loss: 0.5803 - val_binary_accuracy: 0.9189\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31499\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 51s 491ms/step - loss: 0.0380 - binary_accuracy: 0.9890 - val_loss: 0.0429 - val_binary_accuracy: 0.9860\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31499 to 0.04294, saving model to check_points/resnet50/model.h5\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 51s 491ms/step - loss: 0.0284 - binary_accuracy: 0.9925 - val_loss: 0.0938 - val_binary_accuracy: 0.9692\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04294\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 51s 490ms/step - loss: 0.0197 - binary_accuracy: 0.9947 - val_loss: 0.0072 - val_binary_accuracy: 0.9986\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04294 to 0.00724, saving model to check_points/resnet50/model.h5\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 51s 487ms/step - loss: 0.0184 - binary_accuracy: 0.9953 - val_loss: 3.9721 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00724\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 51s 493ms/step - loss: 0.0171 - binary_accuracy: 0.9950 - val_loss: 5.5177 - val_binary_accuracy: 0.6420\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00724\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 51s 490ms/step - loss: 0.0160 - binary_accuracy: 0.9964 - val_loss: 11.4626 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00724\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 51s 492ms/step - loss: 0.0204 - binary_accuracy: 0.9935 - val_loss: 11.3408 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00724\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 51s 488ms/step - loss: 0.0266 - binary_accuracy: 0.9908 - val_loss: 24.6286 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00724\n",
      "Epoch 17/20\n",
      "104/104 [==============================] - 51s 490ms/step - loss: 0.0170 - binary_accuracy: 0.9952 - val_loss: 15.1736 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00724\n",
      "Epoch 18/20\n",
      "104/104 [==============================] - 51s 490ms/step - loss: 0.0154 - binary_accuracy: 0.9953 - val_loss: 0.1929 - val_binary_accuracy: 0.9329\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00724\n",
      "Epoch 19/20\n",
      "104/104 [==============================] - 51s 489ms/step - loss: 0.0150 - binary_accuracy: 0.9964 - val_loss: 0.2910 - val_binary_accuracy: 0.8937\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00724\n",
      "Epoch 20/20\n",
      "104/104 [==============================] - 51s 490ms/step - loss: 0.0205 - binary_accuracy: 0.9947 - val_loss: 8.8525 - val_binary_accuracy: 0.6336\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00724\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "history = model.fit(\n",
    "  normalized_trn_ds,\n",
    "  validation_data=normalized_test_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=callbacks_list\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "02_tf_img_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a4d31c7726be9b170def711a1927a3254c0727bac55ffe5bd7861e35b9f9b7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
