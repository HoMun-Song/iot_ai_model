{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daf19c0-1ad7-4654-9632-e6fd00680367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from model import Unet\n",
    "from dataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae864540-4e64-4515-9dd9-b9228e26fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d93f077-3c3b-47f3-9178-0c7bf61b8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = '/home/workspace/iot_ai_model/check_points/unet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d27a44f-72ea-4170-86c1-9544c11af603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/workspace/iot_ai_model/dataset/supervisely_person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8077ce-b35f-4740-98ba-2550615b4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(os.path.join(data_path,\"**/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535b228a-8d07-4d6f-b798-ca922610bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b201104-b631-43fd-9251-972adcd18bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "images Loading: 2667it [01:12, 36.86it/s] \n",
      "masks Loading: 2667it [00:38, 69.44it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = ImageDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2c6805-c5bc-4657-a679-47723f1b2d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:22:15,384 - trn: 2133, val: 534\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "trn_size = int(dataset_size * 0.8)\n",
    "val_size = dataset_size - trn_size\n",
    "trn_ds, val_ds = random_split(dataset, [trn_size, val_size])\n",
    "trn_loader = torch.utils.data.DataLoader(trn_ds, batch_size= BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size= BATCH_SIZE, shuffle=False)\n",
    "logger.info(f'trn: {len(trn_ds)}, val: {len(val_ds)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e2f00b-fb1d-4415-b579-eb8acefdb382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:22:16,117 - Load on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f'Load on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dabd2eed-f6f4-469d-839b-598b66ca3be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:22:18,623 - loaded model (params 5685495)\n"
     ]
    }
   ],
   "source": [
    "model = Unet().to(device)\n",
    "params_cnt = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f'loaded model (params {params_cnt})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "951049de-f76e-41a4-9276-3d1b3e1db030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # inputs[inputs > 0.5] = 1\n",
    "        # inputs[inputs <= 0.5] = 0\n",
    "        # inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96403b83-de4a-406b-ab46-7d50d7008d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = DiceLoss()\n",
    "criterion2 = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c099570c-e4de-4177-afb6-1aaee884acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader, criterion, optimizer, device, half = False):\n",
    "    loss = .0\n",
    "    acc = .0\n",
    "    correct = 0\n",
    "    start_time = time()\n",
    "    \n",
    "    progress = tqdm(dataloader)\n",
    "    for path, data, target in progress:\n",
    "        data = data.to(device).type(torch.float32)\n",
    "        target = target.to(device).type(torch.float32)\n",
    "        \n",
    "        output = model(data)\n",
    "        output = output.squeeze(dim=1)\n",
    "        \n",
    "        loss1 = criterion(output, target)\n",
    "        loss2 = criterion2(output, target)\n",
    "        \n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        if model.training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        loss += loss\n",
    "\n",
    "    # acc = (correct/len(dataloader.dataset))\n",
    "    loss = loss/len(dataloader.dataset)\n",
    "    logger.info(\"{}, duration:{:6.1f}s, loss:{:.4f}\".format(('trn' if model.training else 'val'), \n",
    "                                                                         time()-start_time, \n",
    "                                                                         loss ))\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47b6416e-3aa9-47d5-879d-f8e91f8c453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840827f1-caa7-4aab-a920-12eabfa5e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(dataset):\n",
    "    id = np.random.randint(len(dataset))\n",
    "    path, image, mask = dataset[id]\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5b6d2c4-f1d9-45a4-afc9-d8c8adf35058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tensor_to_img(tensor):\n",
    "    img = tensor.cpu().detach().numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    return img\n",
    "    \n",
    "def convert_img_to_tensor(img, device = 'cpu'):\n",
    "    return torch.tensor(img.reshape(1,3,256,256)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bcddc44-4772-450a-b208-c7cb8989efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, alpha=1, title=None):\n",
    "    plt.imshow(image, alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b0a060-f16e-43ae-9cb6-7567ebef7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataset, n_images=1):\n",
    "    for i in range(n_images):\n",
    "        plt.figure(figsize=(10,8))\n",
    "        \n",
    "        img, mask = get_random_data(dataset)\n",
    "        tensor = convert_img_to_tensor(img, device= device)\n",
    "        pred_mask = model(tensor)\n",
    "        \n",
    "        plt.subplot(1,3,1)\n",
    "        img = np.transpose(img, (1,2,0))\n",
    "        show_image(img, title='Original Image')\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        mask = np.transpose(mask, (1,2,0))\n",
    "        show_image(mask, title='Original Mask')\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        pred_img = convert_tensor_to_img(pred_mask[0])\n",
    "        show_image(pred_img, title='Predicted Mask')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "177fb707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:22:18,997 - epoch 1\n",
      "  0%|          | 0/67 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 3, 256, 256]], which is output 0 of SigmoidBackward0, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8f826b26427e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrn_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9e19e37f29d5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, dataloader, criterion, optimizer, device, half)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 3, 256, 256]], which is output 0 of SigmoidBackward0, is at version 2; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "trn_loss = []\n",
    "val_loss = []\n",
    "\n",
    "half = False\n",
    "\n",
    "min_loss = 99999.\n",
    "early_count = 0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    logger.info(f'epoch {epoch}')\n",
    "\n",
    "    model.train()\n",
    "    loss = fit(model, trn_loader, criterion, optimizer, device, half=half)\n",
    "\n",
    "    trn_loss.append(loss)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = fit(model, val_loader, criterion, optimizer, device, half=half)\n",
    "\n",
    "        # if loss >= min_loss:\n",
    "        #     early_count += 1\n",
    "        #     if early_count >= early_stopping:\n",
    "        #         break\n",
    "        # else:\n",
    "        #     min_loss = loss\n",
    "        #     early_count = 0\n",
    "\n",
    "        if len(val_loss) > 0 and min(val_loss) > loss:\n",
    "            torch.save(model.state_dict(), f\"{checkpoints_path}/model_state_dict_{epoch}_best.pt\")\n",
    "\n",
    "        val_loss.append(loss)\n",
    "    \n",
    "    show_predictions(model, val_ds)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{checkpoints_path}/model_state_dict_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c354a2b-e28e-4514-9381-c6c73bdfa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/workspace/iot_ai_model/dataset/supervisely_person/test_data_list.txt', 'w') as f:\n",
    "    for idx, (filename, _, _) in enumerate(val_ds):\n",
    "        f.write('{},{}\\n'.format(filename.replace('/home/workspace/iot_ai_model/dataset/supervisely_person/', ''), val_ds.dataset.mask_path[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82b0d1-c876-4490-a4e5-a70847d842f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
