{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8965cc6e-b3a8-4a7d-8a22-4503363359d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from datetime import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99eacba4-0128-4676-84eb-da0b9c3a782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 인코더\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=4096, hidden_size=1024, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True,\n",
    "        #                     dropout=0.1, bidirectional=False)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=0.1, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, hidden = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return hidden\n",
    "    \n",
    "## 디코더\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=4096, hidden_size=1024, output_size=4096, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True,\n",
    "#                             dropout=0.1, bidirectional=False)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=0.1, bidirectional=False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.lstm(x, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        prediction = self.fc(output)\n",
    "\n",
    "        return prediction, hidden\n",
    "    \n",
    "## RNN Auto Encoder\n",
    "class RNNAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 window_size: int=1,\n",
    "                 **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        :param input_dim: 변수 Tag 갯수\n",
    "        :param latent_dim: 최종 압축할 차원 크기\n",
    "        :param window_size: 길이\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "        super(RNNAutoEncoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.window_size = window_size\n",
    "\n",
    "        if \"num_layers\" in kwargs:\n",
    "            num_layers = kwargs.pop(\"num_layers\")\n",
    "        else:\n",
    "            num_layers = 1\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.reconstruct_decoder = Decoder(\n",
    "            input_size=input_dim,\n",
    "            output_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, src:torch.Tensor, **kwargs):\n",
    "        batch_size, sequence_length, var_length = src.size()\n",
    "\n",
    "        ## Encoder 넣기\n",
    "        encoder_hidden = self.encoder(src)\n",
    "        \n",
    "        inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "        reconstruct_output = []\n",
    "        temp_input = torch.zeros((batch_size, 1, var_length), dtype=torch.float).to(src.device)\n",
    "        hidden = encoder_hidden\n",
    "        for t in range(sequence_length):\n",
    "            temp_input, hidden = self.reconstruct_decoder(temp_input, hidden)\n",
    "            reconstruct_output.append(temp_input)\n",
    "        reconstruct_output = torch.cat(reconstruct_output, dim=1)[:, inv_idx, :]\n",
    "        \n",
    "        return [reconstruct_output, src]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        \n",
    "        ## MSE loss(Mean squared Error)\n",
    "        loss =F.mse_loss(recons, input)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff4282a-8fd5-406a-8236-0f87a83f281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CurrentDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33eeb304-fe0c-4478-8ebe-00776ba860b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/workspace/iot_ai_model/dataset/current/train/**/normal/*.csv'\n",
    "dataset = CurrentDataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe34cc1-a539-4286-a3f4-02003638f3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19007823-9704-4034-8f28-4b58d22c0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNAutoEncoder(3, 500, num_layers=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e604e5e-d629-4cf4-8012-a7306956b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataloader = DataLoader(dataset,\n",
    "                            batch_size=64,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d855a91c-9d70-4e21-a33e-a261e7c48e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92049089-28be-4a80-b215-c2502dfe0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "hist_loss = []\n",
    "pre_loss = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f558dbfb-30a3-426b-a7a8-b38c9a7ec5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 394/1217 [11:03<23:06,  1.68s/it, loss 98.58082580566406] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-027122d99afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-faba8d45faa9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mtemp_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mreconstruct_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mreconstruct_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruct_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-faba8d45faa9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    progress = tqdm(trn_dataloader)\n",
    "    cost = 0.\n",
    "    for path, cur, target in progress:\n",
    "        cur = cur.cuda()\n",
    "        output, _ = model(cur)\n",
    "        loss = criterion(cur, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress.set_postfix_str(f'loss {loss.item()}')\n",
    "        \n",
    "        cost += loss.item()\n",
    "    avg_loss = cost / len(train_loader)\n",
    "    hist_loss.append(avg_loss)    \n",
    "    progress.set_postfix_str(f'loss {avg_loss}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576f464e-7d96-452a-8fc6-411ab0d78701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59a80e8-d26d-4b63-afb9-b273210f3626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.08704378, 0.37334953, 0.7192736 ],\n",
       "         [0.25851468, 0.08333939, 0.91786107],\n",
       "         [0.61416842, 0.71758518, 0.56501066],\n",
       "         ...,\n",
       "         [0.18090796, 0.07895112, 0.93121052],\n",
       "         [0.39633596, 0.10610315, 0.63402062],\n",
       "         [0.31739749, 0.42837523, 0.71957548]],\n",
       "\n",
       "        [[0.79688461, 0.81463725, 0.81951224],\n",
       "         [0.43310532, 0.72843846, 0.3233063 ],\n",
       "         [0.84818989, 0.36250963, 0.97919309],\n",
       "         ...,\n",
       "         [0.98370834, 0.01058058, 0.74192041],\n",
       "         [0.57554875, 0.05285465, 0.73751619],\n",
       "         [0.99109348, 0.69378585, 0.75760908]],\n",
       "\n",
       "        [[0.57404126, 0.81415867, 0.01540538],\n",
       "         [0.29621688, 0.64454995, 0.93091213],\n",
       "         [0.80338385, 0.98140393, 0.24922374],\n",
       "         ...,\n",
       "         [0.00865711, 0.61437302, 0.94842847],\n",
       "         [0.36159889, 0.27436632, 0.94589492],\n",
       "         [0.75465225, 0.00206451, 0.67654211]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.24829576, 0.36673569, 0.04645826],\n",
       "         [0.73450276, 0.58413347, 0.91377221],\n",
       "         [0.4294318 , 0.81363529, 0.2352411 ],\n",
       "         ...,\n",
       "         [0.9500088 , 0.28512563, 0.53721744],\n",
       "         [0.02046522, 0.17704904, 0.5127068 ],\n",
       "         [0.34554501, 0.36197839, 0.83550659]],\n",
       "\n",
       "        [[0.82459813, 0.77911487, 0.17233271],\n",
       "         [0.65968209, 0.5485499 , 0.97505748],\n",
       "         [0.92073574, 0.21859108, 0.27174714],\n",
       "         ...,\n",
       "         [0.06470494, 0.79300423, 0.77083674],\n",
       "         [0.45912882, 0.15941886, 0.44212466],\n",
       "         [0.83776692, 0.113181  , 0.97852608]],\n",
       "\n",
       "        [[0.23212318, 0.07278359, 0.57345467],\n",
       "         [0.52194518, 0.87965665, 0.29104658],\n",
       "         [0.81329901, 0.43892393, 0.27691564],\n",
       "         ...,\n",
       "         [0.09388563, 0.58284632, 0.54413985],\n",
       "         [0.11094913, 0.13935484, 0.38711305],\n",
       "         [0.7445757 , 0.53092747, 0.6603418 ]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((1,300,300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92ad87-b596-44ee-9df4-af9c6cec7b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
